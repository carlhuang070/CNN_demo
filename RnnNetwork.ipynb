{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "carl after forward statelist\n",
      "[array([[ 0.],\n",
      "       [ 0.]]), array([[ -1.97692043e-06],\n",
      "       [  1.11474772e-04]]), array([[  3.51361288e-05],\n",
      "       [  1.75012993e-04]])]\n",
      "[[ 1.]\n",
      " [ 1.]]\n",
      "start backward\n",
      "[array([[ 0.],\n",
      "       [ 0.]]), array([[ 0.],\n",
      "       [ 0.]]), array([[ 1.],\n",
      "       [ 1.]])]\n",
      "calc_delta_k\n",
      "1\n",
      "[[  3.83899458e-09]\n",
      " [  1.01772478e-09]]\n",
      "backward delta\n",
      "[array([[ 0.],\n",
      "       [ 0.]]), array([[  3.83899458e-09],\n",
      "       [  1.01772478e-09]]), array([[ 1.],\n",
      "       [ 1.]])]\n",
      "orginal grad\n",
      "[array([[ 0.,  0.],\n",
      "       [ 0.,  0.]]), array([[ 0.,  0.],\n",
      "       [ 0.,  0.]]), array([[ 0.,  0.],\n",
      "       [ 0.,  0.]])]\n",
      "backward grad\n",
      "[[ -1.97692043e-06   1.11474772e-04]\n",
      " [ -1.97692043e-06   1.11474772e-04]]\n",
      "after backward:\n",
      "weights(0,0): expected - actural -0.000002 - -0.000002\n",
      "weights(0,1): expected - actural 0.000111 - 0.000111\n",
      "weights(1,0): expected - actural -0.000002 - -0.000002\n",
      "weights(1,1): expected - actural 0.000111 - 0.000111\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from ConvNetwork import IdentityActivator, element_wise_op\n",
    "\n",
    "\n",
    "\n",
    "class RecurrentLayer(object):\n",
    "    def __init__(self, input_width, state_width,\n",
    "                 activator, learning_rate):\n",
    "        self.input_width = input_width\n",
    "        self.state_width = state_width\n",
    "        self.activator = activator\n",
    "        self.learning_rate = learning_rate\n",
    "        self.times = 0       # 当前时刻初始化为t0\n",
    "        self.state_list = [] # 保存各个时刻的state\n",
    "        self.state_list.append(np.zeros(\n",
    "            (state_width, 1)))           # 初始化s0\n",
    "        self.U = np.random.uniform(-1e-4, 1e-4,\n",
    "            (state_width, input_width))  # 初始化U\n",
    "        self.W = np.random.uniform(-1e-4, 1e-4,\n",
    "            (state_width, state_width))  # 初始化W\n",
    "        self.gradient = np.zeros((state_width,state_width))\n",
    "        \n",
    "    def forward(self, input_array):\n",
    "        '''\n",
    "        根据『式2』进行前向计算\n",
    "        '''\n",
    "        self.times += 1\n",
    "        \n",
    "        state = (np.dot(self.U, input_array) +\n",
    "                 np.dot(self.W, self.state_list[-1]))\n",
    "        element_wise_op(state, self.activator.forward)\n",
    "        self.state_list.append(state)\n",
    "        \n",
    "\n",
    "    def backward(self, sensitivity_array, \n",
    "                 activator):\n",
    "        '''\n",
    "        实现BPTT算法\n",
    "        '''\n",
    "        self.calc_delta(sensitivity_array, activator)\n",
    "        self.calc_gradient()\n",
    "        \n",
    "    def calc_delta(self, sensitivity_array, activator):\n",
    "        self.delta_list = []  # 用来保存各个时刻的误差项\n",
    "        for i in range(self.times):\n",
    "            self.delta_list.append(np.zeros(\n",
    "                (self.state_width, 1)))\n",
    "        print(\"start backward\")\n",
    "        self.delta_list.append(sensitivity_array)\n",
    "        print(self.delta_list)\n",
    "        # 迭代计算每个时刻的误差项\n",
    "        for k in range(self.times - 1, 0, -1):\n",
    "            self.calc_delta_k(k, activator)\n",
    "        print(\"backward delta\") \n",
    "        print(self.delta_list)\n",
    "            \n",
    "    def calc_delta_k(self, k, activator):\n",
    "        '''\n",
    "        根据k+1时刻的delta计算k时刻的delta\n",
    "        '''\n",
    "        print(\"calc_delta_k\")\n",
    "        print(k)\n",
    "        state = self.state_list[k+1].copy()\n",
    "        element_wise_op(self.state_list[k+1],\n",
    "                    activator.backward)\n",
    "        self.delta_list[k] = np.dot(\n",
    "            np.dot(self.delta_list[k+1].T, self.W),\n",
    "            np.diag(state[:,0])).T\n",
    "        print(self.delta_list[k])\n",
    "        \n",
    "    def calc_gradient(self):\n",
    "        self.gradient_list = [] # 保存各个时刻的权重梯度\n",
    "        for t in range(self.times + 1):\n",
    "            self.gradient_list.append(np.zeros(\n",
    "                (self.state_width, self.state_width)))\n",
    "        print(\"orginal grad\")\n",
    "        print(self.gradient_list)\n",
    "        \n",
    "        for t in range(self.times, 0, -1):\n",
    "            self.calc_gradient_t(t)\n",
    "        # 实际的梯度是各个时刻梯度之和\n",
    "        #self.gradient = reduce(\n",
    "        #    lambda a, b: a + b, self.gradient_list,\n",
    "        #    self.gradient_list[0]) # [0]被初始化为0且没有被修改过\n",
    "        for i in range(len(self.gradient_list)):   \n",
    "            self.gradient = self.gradient + self.gradient_list[i]\n",
    "        print(\"backward grad\")    \n",
    "        print(self.gradient)\n",
    "        \n",
    "    def calc_gradient_t(self, t):\n",
    "        '''\n",
    "        计算每个时刻t权重的梯度\n",
    "        '''\n",
    "        gradient = np.dot(self.delta_list[t],\n",
    "            self.state_list[t-1].T)\n",
    "        self.gradient_list[t] = gradient\n",
    "        \n",
    "        \n",
    "        \n",
    "    def update(self):\n",
    "        '''\n",
    "        按照梯度下降，更新权重\n",
    "        '''\n",
    "        self.W -= self.learning_rate * self.gradient\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.times = 0       # 当前时刻初始化为t0\n",
    "        self.state_list = [] # 保存各个时刻的state\n",
    "        self.state_list.append(np.zeros(\n",
    "            (self.state_width, 1)))      # 初始化s0\n",
    "\n",
    "def data_set():\n",
    "    x = [np.array([[1], [2], [3]]),\n",
    "         np.array([[2], [3], [4]])]\n",
    "    d = np.array([[1], [2]])\n",
    "    return x, d\n",
    "\n",
    "        \n",
    "def gradient_check():\n",
    "    '''\n",
    "    梯度检查\n",
    "    '''\n",
    "    # 设计一个误差函数，取所有节点输出项之和\n",
    "    error_function = lambda o: o.sum()\n",
    "    rl = RecurrentLayer(3, 2, IdentityActivator(), 1e-3)\n",
    "    # 计算forward值\n",
    "    x, d = data_set()\n",
    "\n",
    "    rl.forward(x[0])\n",
    "    rl.forward(x[1])\n",
    "    print(\"carl after forward statelist\")\n",
    "    print(rl.state_list)\n",
    "\n",
    "    # 求取sensitivity map\n",
    "    sensitivity_array = np.ones(rl.state_list[-1].shape,\n",
    "                                dtype=np.float64)\n",
    "    \n",
    "    print(sensitivity_array)\n",
    " \n",
    "    # 计算梯度\n",
    "    rl.backward(sensitivity_array, IdentityActivator())\n",
    "    print(\"after backward:\")\n",
    "    # 检查梯度\n",
    "    epsilon = 10e-4\n",
    "    for i in range(rl.W.shape[0]):\n",
    "        for j in range(rl.W.shape[1]):\n",
    "            rl.W[i,j] += epsilon\n",
    "            rl.reset_state()\n",
    "            rl.forward(x[0])\n",
    "            rl.forward(x[1])\n",
    "            err1 = error_function(rl.state_list[-1])\n",
    "            rl.W[i,j] -= 2*epsilon\n",
    "            rl.reset_state()\n",
    "            rl.forward(x[0])\n",
    "            rl.forward(x[1])\n",
    "            err2 = error_function(rl.state_list[-1])\n",
    "            expect_grad = (err1 - err2) / (2 * epsilon)\n",
    "            rl.W[i,j] += epsilon\n",
    "            print ('weights(%d,%d): expected - actural %f - %f' % (\n",
    "                i, j, expect_grad, rl.gradient[i,j]))\n",
    "            \n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #train_and_evaluate()\n",
    "    gradient_check()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
